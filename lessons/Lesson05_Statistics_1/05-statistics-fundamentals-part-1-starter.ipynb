{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Statistics Fundamentals, Part1\n",
    "\n",
    "_Authors: Alexander Egorenkov (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "- Refresh some linear algebra so the Sklearn documentation looks more familiar\n",
    "- Use NumPy and Pandas libraries to analyze datasets using basic summary statistics: mean, median, mode, max, min, quartile, inter-quartile range, variance, standard deviation, and correlation\n",
    "- Create data visualizations - including: scatter plots, box plots, and histograms- to discern characteristics and trends in a dataset\n",
    "- Describe the bias and variance of statistical estimators\n",
    "- Identify a normal distribution within a dataset using summary statistics and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# This makes sure that graphs render in your notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE ARE WE IN THE DATA SCIENCE WORKFLOW?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Science Workflow](./assets/images/data-science-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalars, vectors and matrices\n",
    "\n",
    "A **scalar** is a single number.\n",
    "\n",
    "$$a$$\n",
    "\n",
    "A **vector** is several numbers in sequence.\n",
    "\n",
    "$$\\vec{u} = \\left[ \\begin{array}{c}\n",
    "1&3&7\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([1, 3, 7])\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An m x n **matrix** is a rectangular array of numbers with m rows and n columns. Each number in the matrix is an entry. Entries can be denoted $a_{mn}$\n",
    "\n",
    "$$A= \\left[ \\begin{array}{c}\n",
    "a_{11} & a_{12} & ... & a_{1n}  \\\\\n",
    "a_{21} & a_{22} & ... & a_{2n}  \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{m1} & a_{m2} & ... & a_{mn}\n",
    "\\end{array} \\right]$$\n",
    "$$A \\in \\mathbb{R}^{mn}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1, 3, 7], [4, 6, 3], [2, 5, 6]])\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic matrix algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition and substaction\n",
    "Vector **addition** is straightforward. If two vectors are of equal dimensions:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right],  \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\vec{v} + \\vec{w} =\n",
    "\\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] + \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "1+1 \\\\\n",
    "3+0 \\\\\n",
    "7+1\n",
    "\\end{array} \\right] = \n",
    "\\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "8\n",
    "\\end{array} \\right]\n",
    "$\n",
    "\n",
    "(Subtraction is similar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v + w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar multiplication\n",
    "We scale a vector with **scalar multiplication**, multiplying a vector by a scalar (single quantity):\n",
    "\n",
    "$ 2 \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2*1 \\\\\n",
    "2*3 \\\\\n",
    "2*7\n",
    "\\end{array} \\right] = \n",
    " \\left[ \\begin{array}{c}\n",
    "2 \\\\\n",
    "6 \\\\\n",
    "14\n",
    "\\end{array} \\right]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*np.array([1, 3, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product\n",
    "The **dot product** of two _n_-dimensional vectors is:\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} =\\sum _{i=1}^{n}v_{i}w_{i}=v_{1}w_{1}+v_{2}w_{2}+\\cdots +v_{n}w_{n} $\n",
    "\n",
    "So, if:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "7\n",
    "\\end{array} \\right], \\vec{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$ \\vec{v} \\cdot \\vec{w} = 1*1 + 3*0 + 7*1 = 8 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1, 3, 7])\n",
    "w = np.array([1, 0, 1])\n",
    "v.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "**Matrix multiplication**, $A_{mn} * B_{ij}$, is valid when the left matrix has the same number of columns as the right matrix has rows ($n = i$). Each entry is the dot product of corresponding row and column vectors.\n",
    "\n",
    "![](./assets/images/matrix-multiply-a.gif)\n",
    "(Image: mathisfun.com!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "A.dot(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector norm\n",
    "The **magnitude** of a vector $\\vec{v} \\in \\mathbb{R}^{n}$ in is interpretable as its length in n-dimensional space, and is calculable via the Euclidean distance:\n",
    "\n",
    "$\\vec{v} = \\left[ \\begin{array}{c}\n",
    "v_{1} \\\\\n",
    "v_{2} \\\\\n",
    "\\vdots \\\\\n",
    "v_{n}\n",
    "\\end{array} \\right]$\n",
    "\n",
    "then $\\| \\vec{v} \\| = \\sqrt{v_{1}^{2} + v_{2}^{2} + ... + v_{n}^{2}} = \\sqrt{v^Tv}$\n",
    "\n",
    "E.g. if $\\vec{v} = \n",
    "\\left[ \\begin{array}{c}\n",
    "3 \\\\\n",
    "4\n",
    "\\end{array} \\right]$, then $\\| \\vec{v} \\| = \\sqrt{3^{2} + 4^{2}} = 5$\n",
    "\n",
    "This is also called the vector **norm**. You will see this often in machine learning as least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications to machine learning\n",
    "### Distance between actual values and predicted values\n",
    "We often need to know the difference between predicted values and actual values.\n",
    "We calculate this as:\n",
    "$$\\| \\vec{actual} - \\vec{predicted} \\| =\\sqrt{(actual_1 - predicted_1)^2 + (actual_2 - predict_2)^2}$$\n",
    "### Mean Squared Error\n",
    "Most of the time it's easier to read the average distance between predicted values and actual values.\n",
    "$$\\frac{1} {n} \\| \\vec{y} - f(X) \\|$$\n",
    "### Least squares\n",
    "Many machine learning models are composed in the following form:\n",
    "$$\\min \\| \\vec{y} - f(X) \\|$$\n",
    "The goal is to minimize the distance between model predictions and actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this in sklearn http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the titanic dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODEALONG\n",
    "Objective: Read in the Titanic data and look at a few summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('../../../dataset/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preview columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the column data types?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at the first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we preview the plcass variable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull up descriptive statistics for each variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uh oh, we have some missing values, but we won't do anything with them for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REAL WORLD APPLICATION - Preview data and temporarily clean up missing values\n",
    "\n",
    "- Whenever you get a new dataset, the fastest way to find mistakes and inconsistencies is to look at the descriptive statistics\n",
    "  - If anything look too high or too low relative to your experience, there may be issues with the data collection\n",
    "- Your data may have a lot of missing values and may need to be cleaned meticulously before being combined with other data\n",
    "  - You can take a quick average or moving average to smooth out the data and combine that to preview your results before you embark on your much longer data cleaning journey\n",
    "  - Sometimes filling in missing values with their means or medians will be the best solution for dealing with missing data other times you may want to drop the offending rows or do real imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATISTICS FUNDAMENTALS\n",
    "Objective: Review mean, median, mode, interquartile-range, variance, and standard deviation in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A QUICK REVIEW OF NOTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of a constant, k,  n times\n",
    "$$\\sum_{i=1}^nk$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k + k + k + k + ... + k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all numbers from 1 up to n:\n",
    "$$\\sum_{i=1}^ni$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 + 2 + 3 + ... + n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all x from the first x entry to the nth x entry:\n",
    "$$\\sum_{i=0}^nx_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_1 + x_2 + x_3 + ... + x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codealong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of 7 4s using base Python\n",
    "print \"Sum of 7 4s:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of 7 4s using NumPy\n",
    "print \"Sum of 7 4s:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of 1 through 10 using base Python\n",
    "print \"Sum of 1 through 10:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the titanic.fare column compute the total fare paid by passengers\n",
    "print \"Total fare using Numpy:\",\n",
    "print \"Total fare using Pandas:\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEASURES OF CENTRAL TENDENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean\n",
    "- median\n",
    "- mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEAN\n",
    "The mean, also known as an average or the expected value is defined as:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEDIAN\n",
    "The median refers to the midpoint in a series of numbers.\n",
    "\n",
    "$$ 0,1,2,[3],5,5,9 $$\n",
    "\n",
    "$$ 1,3,4,[4,5],5,5,7 $$\n",
    "\n",
    "To find the median:\n",
    "- Arrange the numbers in order smallest to \n",
    "  largest.\n",
    "\n",
    "- If there is an odd number of values, the \n",
    "  middle value is the median.\n",
    "\n",
    "- If there is an even number of values, the \n",
    "  average of the middle two values is the \n",
    "  median.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODE\n",
    "The mode of a set of values is the value that occurs most often.\n",
    "A set of values may have more than one mode or no mode.\n",
    "\n",
    "$$1,0,1,5,7,8,9,3,4,1$$ 1 is the mode since it occurs the most often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codealong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using base Python\n",
    "print \"Mean titanic fare:\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using NumPy\n",
    "print \"Mean titanic fare:\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of the titanic.fare series using Pandas\n",
    "print \"Mean titanic fare:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the median fare paid (using Pandas)?\n",
    "print \"Median titanic fare:\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The mean and median are not the same, does this tell you anything about the fares?\n",
    "# Let's discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to find the most common fare paid on the Titanic\n",
    "print \"The most common fare is:\",\n",
    "# Notice that this returns a series instead of a single number, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MATH REVIEW\n",
    "**How do we measure distance?**\n",
    "\n",
    "One method is two take the difference between two points\n",
    "$$X_2 - X_1$$\n",
    "\n",
    "However, this can be inconvenient due to negative numbers.\n",
    "\n",
    "We often use this square root trick to deal with negative numbers\n",
    "$$\\sqrt{(X_2-X_1)^2}$$\n",
    "\n",
    "**What about distance in multiple dimensions?**\n",
    "\n",
    "We can turn to the Pythagorean theorem\n",
    "$$a^2 + b^2 = c^2$$\n",
    "\n",
    "To find the distance along a diagnal it is sufficient to measure one dimension at a time\n",
    "$$\\sqrt{a^2 + b^2} = c$$\n",
    "\n",
    "More generally we can write this as (You'll see this in machine learning papers)\n",
    "$$\\|X\\|_2 = \\sqrt{\\sum{x_i^2}} = c$$\n",
    "\n",
    "If we want to work with points rather than distances, we can write\n",
    "$$\\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2} = c$$\n",
    "or\n",
    "$$\\sqrt{\\sum{(x_i - y_i)^2}} = c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNOWLEDGE CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How much younger is the youngest person on the titanic compared to the average person on the titanic?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the square root trick to make sure we have a positive distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STANDARD DEVIATION & VARIANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation (SD, Ïƒ for population, s for sample)  is a measure that is used to quantify the amount of variation or dispersion of a set of data values.\n",
    "\n",
    "Standard deviation is the square root of variance.\n",
    "$$variance = \\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "$$s = \\sqrt{\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can be a lot to take in so let's break it down in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 5 rows of titanic age data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean by hand\n",
    "mean = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance by hand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our first model from scratch. We'll predict the fare column in the titanic data. What data will we use? Actually, none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest model we can build is an estimation of the mean, median, or most common value. If we have no feature matrix and only an outcome, this is the best approach to make a prediction using only empirical data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems silly, but we'll actually use it all the time to create a baseline of how well we do with no data, and whether our more sophisticated models make an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Fare column from the titanic data and store as y\n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stored predictions in y_pred\n",
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the least squares (euclidean distance) formula to see how close our predictions are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared Error is really hard to read, Let's look at Mean Squared Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SHORT INTRO TO BIAS AND VARIANCE (There will be more intros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, **Bias** shows how on target a model is in its predictions.\n",
    "\n",
    "**Variance** shows how reliable a model is in its performance.\n",
    "\n",
    "These characteristics have important interactions, but we will save that for later.\n",
    "\n",
    "![Bias and Variance](./assets/images/biasVsVarianceImage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we just calculated Mean Squared Error to see how good our prediction was? It turns out we can do this for any statistical estimator, including means, variances, and machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even decompose Mean Squared Error to identify where the source of error comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notation $f$ refers to a perfect model while $\\hat{f}$ refers to our model.\n",
    "\n",
    "**Bias**\n",
    "\n",
    "Error due to bias is calculated at the difference between the expected prediction of our model and the correct value we are trying to predict.\n",
    "$$Bias = E[\\hat{f}(x)] - f(x)$$\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Error due to variance is taken as the variability of a model prediction for a given point.\n",
    "\n",
    "$$Variance = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$$\n",
    "\n",
    "**Mean Squared Error**\n",
    "$$MSE(\\hat{f}(x)) = Var(\\hat{f}(x)) + Bias(\\hat{f}(x),f(x))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic will come up again, it's enough for now to know that we can decompose MSE into Bias of the estimator and Variance of the estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using Bessel's correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rarely practical to measure every single item in a population to gather a statistic. We will usually sample a few items and use those to infer a population value.\n",
    "\n",
    "For example, we can take a class of 200 students and measure their height, but rather than measuring everyone, we select students at random to estimate the average height in the class and the variance of the height in the class.\n",
    "\n",
    "We know we can take the mean as follows:\n",
    "$$E[X] = \\bar{X} =\\frac 1n\\sum_{i=1}^nx_i$$\n",
    "\n",
    "What about the variance?\n",
    "\n",
    "Intuitively and by definition, population variance looks like this (the average distance from the mean):\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n}$$\n",
    "\n",
    "It's actually better to use the following for a sample (why?):\n",
    "\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n-1}$$\n",
    "\n",
    "In some cases, we may even use:\n",
    "\n",
    "$$\\frac {\\sum{(x_i - \\bar{X})^2}} {n+1}$$\n",
    "\n",
    "Detailed explanations can be found here (Spoiler alert, Stats 101 is over-simplified):\n",
    "- https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "- https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heights = np.random.rand(200) + 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_means(sample_size):\n",
    "    true_mean = np.mean(heights)\n",
    "    mean_heights = []\n",
    "    for n in range(5,sample_size):\n",
    "        for j in range(30):\n",
    "            mean_height = np.mean(np.random.choice(heights, n, replace=False))\n",
    "            mean_heights.append((n, mean_height))\n",
    "    sample_height = pd.DataFrame(mean_heights, columns=['sample_size', 'height'])\n",
    "    sample_height.plot.scatter(x='sample_size', y='height', figsize=(14, 4), alpha=0.5)\n",
    "    plt.axhline(y=true_mean, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Mean Estimator\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_variances(sample_size):\n",
    "    true_variance = np.var(heights)\n",
    "    var_heights = []\n",
    "    for n in range(5,sample_size):\n",
    "        for j in range(30):\n",
    "            var_height1 = np.var(np.random.choice(heights, n, replace=False), ddof=0)\n",
    "            var_height2 = np.var(np.random.choice(heights, n, replace=False), ddof=1)\n",
    "            var_height3 = np.var(np.random.choice(heights, n, replace=False), ddof=-1)\n",
    "            var_heights.append((n, var_height1, var_height2, var_height3))\n",
    "    sample_var = pd.DataFrame(var_heights, columns=['sample_size', 'variance1', 'variance2', 'variance3'])\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance1', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Population Variance Estimator (n)\")\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance3', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Biased Sample Variance Estimator (n+1)\")\n",
    "    sample_var.plot.scatter(x='sample_size', y='variance2', figsize=(14, 3), alpha=0.5)\n",
    "    plt.axhline(y=true_variance, c='r')\n",
    "    plt.title(\"The Bias and Variance of the Sample Variance Estimator (n-1)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_means, sample_size=(5,200));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The red line above is the true average height, but because we don't want to ask 200 people about their height, we take a samples.\n",
    "\n",
    "- The blue dots show the estimate of the average height after taking a sample. To give us an idea of how sampling works, we simulate taking multiple sample.\n",
    "\n",
    "- The X axis shows the sample size we take, the blue dots show the likely average heights we'll conclude for a given sample size.\n",
    "\n",
    "- Even though the true average height is around 7 feet, a small sample may lead us to think that it's actually 6.7 or 7.3 feet. \n",
    "\n",
    "- Notice that the red line is in the center of our estimates. On average, we are correct and have no bias.\n",
    "\n",
    "- If we take a larger sample size we get a better estimate. Meaning that the variance of our estimate gets smaller with larger samples sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_variances, sample_size=(5,200));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not all estimators are created equal.\n",
    "\n",
    "- The red line shows the true variance of height\n",
    "\n",
    "- The top graph is the Population Variance estimator, while the bottom graph is the Sample Variance estimator.\n",
    "\n",
    "- This is very subtle, but notice that the Population Variance estimator is not centered on the red line. It's actually biased and consistently underestimates the true variance, especially at low sample sizes.\n",
    "\n",
    "- You may also notice that the scatter of of Population Variance estimator is smaller. That means the variance of the Population Variance estimator is smaller. That phrase can be really confusing, it's the variability of the estimator. \n",
    "\n",
    "- Play around with the sliders to get a good view of the graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION AND ASSOCIATION\n",
    "Correlation measures how variables related to each other.\n",
    "\n",
    "Typical when we talk about the pearson correlation coefficient which is a measure of **linear** association\n",
    "\n",
    "We refer to perfect correlation as colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example correlation values](./assets/images/correlation_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODEALONG - Correlation in Pandas\n",
    "Objective: Explore options for measuring and visualizing correlation in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the correlation matrix for all titanic variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation of just survived and fare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seaborn to plot a correlation heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a closer look at survived and fare using a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is correlation a good way to inspect the association of fare and survival?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS THIS NORMAL?\n",
    "Objective: Introduce normal (gaussian distributions) and how to identify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Math Review\n",
    "- What is an event space?\n",
    "  - A listing of all possible occurances\n",
    "- What is a probability distribution?\n",
    "  - A function that describes how events occur in an event space\n",
    "- What are general properties of probability distributions?\n",
    "  - All probabilities of an event are between 0 and 1\n",
    "  - The probability that something occurs is almost certain or 1.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### THE NORMAL DISTRIBUTION\n",
    "- A normal distribution is often a key assumption to many models.\n",
    "  - In practice, if the normal distribution assumption is not met, it's not the end of the world. Your model is just less efficient in most cases.\n",
    "\n",
    "- The normal distribution depends upon the mean and the standard deviation.\n",
    "\n",
    "- The mean determines the center of the distribution.  The standard deviation determines the height and width of the distribution.\n",
    "\n",
    "- Normal distributions are symmetric, bell-shaped curves.\n",
    "\n",
    "- When the standard deviation is large, the curve is short and wide.\n",
    "\n",
    "- When the standard deviation is small, the curve it tall and narrow.\n",
    "\n",
    "![normal distribution](./assets/images/normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### WHY DO WE THINK ABOUT NORMAL DISTRIBUTIONS?\n",
    "- Show up in nature very often\n",
    "- Aggregated processes tend to distribute normally regardless of their underlying distribution provided that the processes are uncorrelated or weakly correlated (Central Limit Theorem)\n",
    "- Good simplification that makes it easy to make approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of several random normal samples from numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  SKEWNESS\n",
    "- Skewness is a measure of the asymmetry of the distribution of a random variable about its mean.\n",
    "- Skewness can be positive or negative, or even undefined.\n",
    "- Notice that the mean, median, and mode are the same when there is no skew\n",
    "![skewness](./assets/images/skewness---mean-median-mode.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a lognormal distribution generated with numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Real World Application - When mindfullness beats complexity\n",
    "- Skewness is surprisingly important.\n",
    "- Most algorithms implicitly use the mean by default when making approximations.\n",
    "- If you know your data is heavily skewed you may have to either transform your data or set your algorithms to work with the median.\n",
    "- In the DIDI tech challenge, changing a few default options quickly put you in the 80th percentile, ahead of some very brilliant programmers who missed the basics. This amount to switch the algorithm from estimating a mean to estimating a median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KURTOSIS\n",
    "- Kurtosis is a measure of whether the data are peaked or flat relative to a normal distribution.\n",
    "- Datasets with high kurtosis tend to have a distinct peak near the mean, decline rather rapidly, and have heavy tails. \n",
    "\n",
    "![kurtosis](./assets/images/kurtosis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Real World Application - Risk Analysis\n",
    "- Long-tailed distributions with high kurtosis elude intuition, we naturally think the event is too improbable to pay attention to\n",
    "- It's often the case that there is a a large cost associated with the very low probability event as is the case with hurricane damage\n",
    "- It's unlikely you will get hit by a category 5 hurricane, but when you do, the damage is catastrophic\n",
    "- Pay attention to what happens at the tails and whether it influences the problem at hand\n",
    "- In these cases understanding the costs may be more important than understanding the risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETERMINING THE DISTRIBUTION OF YOUR DATA\n",
    "\n",
    "Objective: Introduce histograms and density plots in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/distributions.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all variables in titanic using histograms\n",
    "titanic.hist(figsize=(14, 8), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all histograms can be unweildly, boxplots can be more concise\n",
    "titanic.plot.box(showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at the titanic data variables\n",
    "# Are any of them normal?\n",
    "# Are any skewed?\n",
    "# How might this affect our modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/visualization_flow_chart.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC REVIEW\n",
    "- We covered several different types of summary statistics, what are they?\n",
    "- We covered three different types of visualizations, which ones?\n",
    "- Describe bias and variance and why they are important.\n",
    "- What are some important characteristics of distributions?\n",
    "\n",
    "**Any further questions?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
